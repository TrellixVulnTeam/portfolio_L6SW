{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos carregar o modelo que já temos treinado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "restore_saver = tf.train.import_meta_graph(\"./mnist-0-4-tf.model.meta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.get_default_graph().get_tensor_by_name(\"X:0\")\n",
    "y = tf.get_default_graph().get_tensor_by_name(\"y:0\")\n",
    "loss = tf.get_default_graph().get_tensor_by_name(\"loss:0\")\n",
    "y_proba = tf.get_default_graph().get_tensor_by_name(\"y_proba:0\")\n",
    "logits = y_proba.op.inputs[0]\n",
    "accuracy = tf.get_default_graph().get_tensor_by_name(\"accuracy:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para que possamos congelar as camadas inferiores, vamos remocer suas variáveis da lista de variáveis treinávis (trainables) do otimizador, deixando apenas a camada saída ocmo treinável."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\vinicius\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "output_layer_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"logits\")\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate, name=\"Adam2\")\n",
    "training_op = optimizer.minimize(loss, var_list=output_layer_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "five_frozen_saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos treinar essa nova DNN em dígitos de 5 a 9 (usamos a mesma camada de saída pois ainda temos o mesmo formato, 5 dígitos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos carregar os dados, note que removemos 5 das labels porque o tensorflow espera inteiros de 0 a n_classes - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-9-9caf0c26c00b>:1: load_dataset (from tensorflow.contrib.learn.python.learn.datasets) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data.\n",
      "WARNING:tensorflow:From C:\\Users\\vinicius\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\__init__.py:80: load_mnist (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\vinicius\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:300: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\vinicius\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\vinicius\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From C:\\Users\\vinicius\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST-data\\train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From C:\\Users\\vinicius\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST-data\\train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST-data\\t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST-data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\vinicius\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n",
    "train_data = mnist.train.images # Returns np.array\n",
    "train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n",
    "eval_data = mnist.test.images # Returns np.array\n",
    "eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)\n",
    "\n",
    "X_valid, X_train = train_data[:5000], train_data[5000:]\n",
    "y_valid, y_train = train_labels[:5000], train_labels[5000:]\n",
    "\n",
    "X_train1 = X_train[y_train < 5]\n",
    "y_train1 = y_train[y_train < 5]\n",
    "X_valid1 = X_valid[y_valid < 5]\n",
    "y_valid1 = y_valid[y_valid < 5]\n",
    "X_test1 = eval_data[eval_labels < 5]\n",
    "y_test1 = eval_labels[eval_labels < 5]\n",
    "\n",
    "X_train2 = X_train[y_train >= 5]\n",
    "y_train2 = y_train[y_train >= 5] - 5\n",
    "X_valid2 = X_valid[y_valid >= 5]\n",
    "y_valid2 = y_valid[y_valid >= 5] - 5\n",
    "X_test2 = eval_data[eval_labels >= 5]\n",
    "y_test2 = eval_labels[eval_labels >= 5] - 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1000\n",
    "batch_size = 20\n",
    "\n",
    "max_checks_without_progress = 20\n",
    "checks_without_progress = 0\n",
    "best_loss = np.infty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./mnist-0-4-tf.model\n",
      "0\tValidation loss: 0.422767\tBest loss: 0.422767\tAccuracy: 85.99%\n",
      "1\tValidation loss: 0.359880\tBest loss: 0.359880\tAccuracy: 89.08%\n",
      "2\tValidation loss: 0.329546\tBest loss: 0.329546\tAccuracy: 89.78%\n",
      "3\tValidation loss: 0.314028\tBest loss: 0.314028\tAccuracy: 90.28%\n",
      "4\tValidation loss: 0.314009\tBest loss: 0.314009\tAccuracy: 89.82%\n",
      "5\tValidation loss: 0.301106\tBest loss: 0.301106\tAccuracy: 90.11%\n",
      "6\tValidation loss: 0.294571\tBest loss: 0.294571\tAccuracy: 90.65%\n",
      "7\tValidation loss: 0.286487\tBest loss: 0.286487\tAccuracy: 90.73%\n",
      "8\tValidation loss: 0.299072\tBest loss: 0.286487\tAccuracy: 90.23%\n",
      "9\tValidation loss: 0.287135\tBest loss: 0.286487\tAccuracy: 91.02%\n",
      "10\tValidation loss: 0.296370\tBest loss: 0.286487\tAccuracy: 90.03%\n",
      "11\tValidation loss: 0.284234\tBest loss: 0.284234\tAccuracy: 90.94%\n",
      "12\tValidation loss: 0.284318\tBest loss: 0.284234\tAccuracy: 91.02%\n",
      "13\tValidation loss: 0.288726\tBest loss: 0.284234\tAccuracy: 90.52%\n",
      "14\tValidation loss: 0.279819\tBest loss: 0.279819\tAccuracy: 90.98%\n",
      "15\tValidation loss: 0.274168\tBest loss: 0.274168\tAccuracy: 91.14%\n",
      "16\tValidation loss: 0.284262\tBest loss: 0.274168\tAccuracy: 90.73%\n",
      "17\tValidation loss: 0.277986\tBest loss: 0.274168\tAccuracy: 91.10%\n",
      "18\tValidation loss: 0.287344\tBest loss: 0.274168\tAccuracy: 90.81%\n",
      "19\tValidation loss: 0.279465\tBest loss: 0.274168\tAccuracy: 90.81%\n",
      "20\tValidation loss: 0.283550\tBest loss: 0.274168\tAccuracy: 90.89%\n",
      "21\tValidation loss: 0.281905\tBest loss: 0.274168\tAccuracy: 90.65%\n",
      "22\tValidation loss: 0.281676\tBest loss: 0.274168\tAccuracy: 90.52%\n",
      "23\tValidation loss: 0.283082\tBest loss: 0.274168\tAccuracy: 90.85%\n",
      "24\tValidation loss: 0.281169\tBest loss: 0.274168\tAccuracy: 90.98%\n",
      "25\tValidation loss: 0.280501\tBest loss: 0.274168\tAccuracy: 90.94%\n",
      "26\tValidation loss: 0.277226\tBest loss: 0.274168\tAccuracy: 90.85%\n",
      "27\tValidation loss: 0.282826\tBest loss: 0.274168\tAccuracy: 90.52%\n",
      "28\tValidation loss: 0.276596\tBest loss: 0.274168\tAccuracy: 91.06%\n",
      "29\tValidation loss: 0.277388\tBest loss: 0.274168\tAccuracy: 90.89%\n",
      "30\tValidation loss: 0.272762\tBest loss: 0.272762\tAccuracy: 91.14%\n",
      "31\tValidation loss: 0.284331\tBest loss: 0.272762\tAccuracy: 90.56%\n",
      "32\tValidation loss: 0.278931\tBest loss: 0.272762\tAccuracy: 90.94%\n",
      "33\tValidation loss: 0.273220\tBest loss: 0.272762\tAccuracy: 91.26%\n",
      "34\tValidation loss: 0.276675\tBest loss: 0.272762\tAccuracy: 90.77%\n",
      "35\tValidation loss: 0.272318\tBest loss: 0.272318\tAccuracy: 91.06%\n",
      "36\tValidation loss: 0.273612\tBest loss: 0.272318\tAccuracy: 90.85%\n",
      "37\tValidation loss: 0.271970\tBest loss: 0.271970\tAccuracy: 91.10%\n",
      "38\tValidation loss: 0.280253\tBest loss: 0.271970\tAccuracy: 90.48%\n",
      "39\tValidation loss: 0.276144\tBest loss: 0.271970\tAccuracy: 90.89%\n",
      "40\tValidation loss: 0.272447\tBest loss: 0.271970\tAccuracy: 91.02%\n",
      "41\tValidation loss: 0.278951\tBest loss: 0.271970\tAccuracy: 90.56%\n",
      "42\tValidation loss: 0.268585\tBest loss: 0.268585\tAccuracy: 91.06%\n",
      "43\tValidation loss: 0.276367\tBest loss: 0.268585\tAccuracy: 90.94%\n",
      "44\tValidation loss: 0.280871\tBest loss: 0.268585\tAccuracy: 90.85%\n",
      "45\tValidation loss: 0.275599\tBest loss: 0.268585\tAccuracy: 90.85%\n",
      "46\tValidation loss: 0.284872\tBest loss: 0.268585\tAccuracy: 90.44%\n",
      "47\tValidation loss: 0.275586\tBest loss: 0.268585\tAccuracy: 90.89%\n",
      "48\tValidation loss: 0.272674\tBest loss: 0.268585\tAccuracy: 90.81%\n",
      "49\tValidation loss: 0.276370\tBest loss: 0.268585\tAccuracy: 90.89%\n",
      "50\tValidation loss: 0.286653\tBest loss: 0.268585\tAccuracy: 90.69%\n",
      "51\tValidation loss: 0.280064\tBest loss: 0.268585\tAccuracy: 90.61%\n",
      "52\tValidation loss: 0.273580\tBest loss: 0.268585\tAccuracy: 91.02%\n",
      "53\tValidation loss: 0.277375\tBest loss: 0.268585\tAccuracy: 90.69%\n",
      "54\tValidation loss: 0.275049\tBest loss: 0.268585\tAccuracy: 90.94%\n",
      "55\tValidation loss: 0.280937\tBest loss: 0.268585\tAccuracy: 90.61%\n",
      "56\tValidation loss: 0.271846\tBest loss: 0.268585\tAccuracy: 91.14%\n",
      "57\tValidation loss: 0.276259\tBest loss: 0.268585\tAccuracy: 90.94%\n",
      "58\tValidation loss: 0.276040\tBest loss: 0.268585\tAccuracy: 90.94%\n",
      "59\tValidation loss: 0.275615\tBest loss: 0.268585\tAccuracy: 90.98%\n",
      "60\tValidation loss: 0.286992\tBest loss: 0.268585\tAccuracy: 90.40%\n",
      "61\tValidation loss: 0.276997\tBest loss: 0.268585\tAccuracy: 90.69%\n",
      "62\tValidation loss: 0.276563\tBest loss: 0.268585\tAccuracy: 90.94%\n",
      "63\tValidation loss: 0.267279\tBest loss: 0.267279\tAccuracy: 91.14%\n",
      "64\tValidation loss: 0.276738\tBest loss: 0.267279\tAccuracy: 90.98%\n",
      "65\tValidation loss: 0.280131\tBest loss: 0.267279\tAccuracy: 90.85%\n",
      "66\tValidation loss: 0.282127\tBest loss: 0.267279\tAccuracy: 90.81%\n",
      "67\tValidation loss: 0.280218\tBest loss: 0.267279\tAccuracy: 90.89%\n",
      "68\tValidation loss: 0.275928\tBest loss: 0.267279\tAccuracy: 90.85%\n",
      "69\tValidation loss: 0.272276\tBest loss: 0.267279\tAccuracy: 90.98%\n",
      "70\tValidation loss: 0.273223\tBest loss: 0.267279\tAccuracy: 91.14%\n",
      "71\tValidation loss: 0.272608\tBest loss: 0.267279\tAccuracy: 90.85%\n",
      "72\tValidation loss: 0.277398\tBest loss: 0.267279\tAccuracy: 90.89%\n",
      "73\tValidation loss: 0.277470\tBest loss: 0.267279\tAccuracy: 91.22%\n",
      "74\tValidation loss: 0.271060\tBest loss: 0.267279\tAccuracy: 91.26%\n",
      "75\tValidation loss: 0.277133\tBest loss: 0.267279\tAccuracy: 90.69%\n",
      "76\tValidation loss: 0.280943\tBest loss: 0.267279\tAccuracy: 90.73%\n",
      "77\tValidation loss: 0.277919\tBest loss: 0.267279\tAccuracy: 90.81%\n",
      "78\tValidation loss: 0.279555\tBest loss: 0.267279\tAccuracy: 90.48%\n",
      "79\tValidation loss: 0.273942\tBest loss: 0.267279\tAccuracy: 91.14%\n",
      "80\tValidation loss: 0.275409\tBest loss: 0.267279\tAccuracy: 91.22%\n",
      "81\tValidation loss: 0.276121\tBest loss: 0.267279\tAccuracy: 90.94%\n",
      "82\tValidation loss: 0.274620\tBest loss: 0.267279\tAccuracy: 91.10%\n",
      "83\tValidation loss: 0.278243\tBest loss: 0.267279\tAccuracy: 90.94%\n",
      "Early stopping!\n",
      "INFO:tensorflow:Restoring parameters from ./my_mnist_model_5_to_9_five_frozen\n",
      "Final test accuracy: 91.07%\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"./mnist-0-4-tf.model\")\n",
    "    for var in output_layer_vars:\n",
    "        var.initializer.run()\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        rnd_idx = np.random.permutation(len(X_train2))\n",
    "        for rnd_indices in np.array_split(rnd_idx, len(X_train2)//batch_size):\n",
    "            X_batch, y_batch = X_train2[rnd_indices], y_train2[rnd_indices]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        loss_val, acc_val = sess.run([loss, accuracy], feed_dict={X: X_valid2, y:y_valid2})\n",
    "        if loss_val < best_loss:\n",
    "            save_path = five_frozen_saver.save(sess, \"./my_mnist_model_5_to_9_five_frozen\")\n",
    "            best_loss = loss_val\n",
    "            checks_without_progress = 0\n",
    "        else:\n",
    "            checks_without_progress += 1\n",
    "            if checks_without_progress > max_checks_without_progress:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "        print(\"{}\\tValidation loss: {:.6f}\\tBest loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "            epoch, loss_val, best_loss, acc_val * 100))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    five_frozen_saver.restore(sess, \"./my_mnist_model_5_to_9_five_frozen\")\n",
    "    acc_test = accuracy.eval(feed_dict={X: X_test2, y: y_test2})\n",
    "    print(\"Final test accuracy: {:.2f}%\".format(acc_test * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste exemplo, a única camada treinável foi a a de saída, ou seja, utilizamos o conhecimento do modelo treinado em dígitos de 0 a 4 e ajustamos apenas uma camada para que ele pudesse aprender a reconhecer outros dígitos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos adicionar uma camada no topo da última camada oculta da rede e retreinar o modelo com uma nova softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.layers import fully_connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "he_init = tf.contrib.layers.variance_scaling_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "n_outputs = 5\n",
    "restore_saver = tf.train.import_meta_graph(\"./mnist-0-4-tf.model.meta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.get_default_graph().get_tensor_by_name(\"X:0\")\n",
    "y = tf.get_default_graph().get_tensor_by_name(\"y:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden5_out = tf.get_default_graph().get_tensor_by_name(\"hidden5/Elu:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_6 = fully_connected(hidden5_out, 100, activation_fn=tf.nn.elu, \n",
    "                            weights_initializer=he_init, scope=\"hidden6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = fully_connected(hidden_6, 5, activation_fn=None, weights_initializer=he_init, \n",
    "                         scope=\"new_logits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_proba = tf.nn.softmax(logits)\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "loss = tf.reduce_mean(xentropy)\n",
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "output_layer_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"hidden6|new_logits\")\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate, name=\"Adam2\")\n",
    "training_op = optimizer.minimize(loss, var_list=output_layer_vars)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "four_frozen_saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1000\n",
    "batch_size = 20\n",
    "\n",
    "max_checks_without_progress = 20\n",
    "checks_without_progress = 0\n",
    "best_loss = np.infty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./mnist-0-4-tf.model\n",
      "0\tValidation loss: 0.295949\tBest loss: 0.295949\tAccuracy: 90.77%\n",
      "1\tValidation loss: 0.259078\tBest loss: 0.259078\tAccuracy: 91.43%\n",
      "2\tValidation loss: 0.217295\tBest loss: 0.217295\tAccuracy: 92.46%\n",
      "3\tValidation loss: 0.224532\tBest loss: 0.217295\tAccuracy: 92.38%\n",
      "4\tValidation loss: 0.187246\tBest loss: 0.187246\tAccuracy: 93.41%\n",
      "5\tValidation loss: 0.178598\tBest loss: 0.178598\tAccuracy: 93.57%\n",
      "6\tValidation loss: 0.197313\tBest loss: 0.178598\tAccuracy: 93.00%\n",
      "7\tValidation loss: 0.181959\tBest loss: 0.178598\tAccuracy: 93.65%\n",
      "8\tValidation loss: 0.177878\tBest loss: 0.177878\tAccuracy: 93.90%\n",
      "9\tValidation loss: 0.163134\tBest loss: 0.163134\tAccuracy: 94.19%\n",
      "10\tValidation loss: 0.164856\tBest loss: 0.163134\tAccuracy: 94.56%\n",
      "11\tValidation loss: 0.186183\tBest loss: 0.163134\tAccuracy: 94.07%\n",
      "12\tValidation loss: 0.177134\tBest loss: 0.163134\tAccuracy: 93.57%\n",
      "13\tValidation loss: 0.151317\tBest loss: 0.151317\tAccuracy: 94.81%\n",
      "14\tValidation loss: 0.157875\tBest loss: 0.151317\tAccuracy: 94.19%\n",
      "15\tValidation loss: 0.167772\tBest loss: 0.151317\tAccuracy: 94.03%\n",
      "16\tValidation loss: 0.164502\tBest loss: 0.151317\tAccuracy: 94.11%\n",
      "17\tValidation loss: 0.158878\tBest loss: 0.151317\tAccuracy: 94.73%\n",
      "18\tValidation loss: 0.181872\tBest loss: 0.151317\tAccuracy: 94.15%\n",
      "19\tValidation loss: 0.161043\tBest loss: 0.151317\tAccuracy: 94.56%\n",
      "20\tValidation loss: 0.174005\tBest loss: 0.151317\tAccuracy: 94.27%\n",
      "21\tValidation loss: 0.152992\tBest loss: 0.151317\tAccuracy: 95.30%\n",
      "22\tValidation loss: 0.171208\tBest loss: 0.151317\tAccuracy: 94.40%\n",
      "23\tValidation loss: 0.164929\tBest loss: 0.151317\tAccuracy: 94.85%\n",
      "24\tValidation loss: 0.156266\tBest loss: 0.151317\tAccuracy: 95.22%\n",
      "25\tValidation loss: 0.150964\tBest loss: 0.150964\tAccuracy: 95.43%\n",
      "26\tValidation loss: 0.171138\tBest loss: 0.150964\tAccuracy: 94.48%\n",
      "27\tValidation loss: 0.167332\tBest loss: 0.150964\tAccuracy: 95.06%\n",
      "28\tValidation loss: 0.166743\tBest loss: 0.150964\tAccuracy: 95.18%\n",
      "29\tValidation loss: 0.162578\tBest loss: 0.150964\tAccuracy: 95.30%\n",
      "30\tValidation loss: 0.192457\tBest loss: 0.150964\tAccuracy: 94.15%\n",
      "31\tValidation loss: 0.174722\tBest loss: 0.150964\tAccuracy: 94.97%\n",
      "32\tValidation loss: 0.171811\tBest loss: 0.150964\tAccuracy: 95.14%\n",
      "33\tValidation loss: 0.154397\tBest loss: 0.150964\tAccuracy: 95.39%\n",
      "34\tValidation loss: 0.161218\tBest loss: 0.150964\tAccuracy: 95.30%\n",
      "35\tValidation loss: 0.161036\tBest loss: 0.150964\tAccuracy: 95.71%\n",
      "36\tValidation loss: 0.166084\tBest loss: 0.150964\tAccuracy: 95.51%\n",
      "37\tValidation loss: 0.161905\tBest loss: 0.150964\tAccuracy: 95.76%\n",
      "38\tValidation loss: 0.171363\tBest loss: 0.150964\tAccuracy: 95.51%\n",
      "39\tValidation loss: 0.183113\tBest loss: 0.150964\tAccuracy: 95.14%\n",
      "40\tValidation loss: 0.181822\tBest loss: 0.150964\tAccuracy: 94.77%\n",
      "41\tValidation loss: 0.169313\tBest loss: 0.150964\tAccuracy: 95.63%\n",
      "42\tValidation loss: 0.187033\tBest loss: 0.150964\tAccuracy: 94.97%\n",
      "43\tValidation loss: 0.176308\tBest loss: 0.150964\tAccuracy: 95.10%\n",
      "44\tValidation loss: 0.189532\tBest loss: 0.150964\tAccuracy: 95.22%\n",
      "45\tValidation loss: 0.176886\tBest loss: 0.150964\tAccuracy: 95.67%\n",
      "Early stopping!\n",
      "INFO:tensorflow:Restoring parameters from ./my_mnist_model_four_frozen\n",
      "Final test accuracy: 94.80%\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"./mnist-0-4-tf.model\")\n",
    "    for var in output_layer_vars:\n",
    "        var.initializer.run()\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        rnd_idx = np.random.permutation(len(X_train2))\n",
    "        for rnd_indices in np.array_split(rnd_idx, len(X_train2)//batch_size):\n",
    "            X_batch, y_batch = X_train2[rnd_indices], y_train2[rnd_indices]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        loss_val, acc_val = sess.run([loss, accuracy], feed_dict={X: X_valid2, y:y_valid2})\n",
    "        if loss_val < best_loss:\n",
    "            save_path = four_frozen_saver.save(sess, \"./my_mnist_model_four_frozen\")\n",
    "            best_loss = loss_val\n",
    "            checks_without_progress = 0\n",
    "        else:\n",
    "            checks_without_progress += 1\n",
    "            if checks_without_progress > max_checks_without_progress:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "        print(\"{}\\tValidation loss: {:.6f}\\tBest loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "            epoch, loss_val, best_loss, acc_val * 100))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    four_frozen_saver.restore(sess, \"./my_mnist_model_four_frozen\")\n",
    "    acc_test = accuracy.eval(feed_dict={X: X_test2, y: y_test2})\n",
    "    print(\"Final test accuracy: {:.2f}%\".format(acc_test * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
